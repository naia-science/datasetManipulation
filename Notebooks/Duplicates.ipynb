{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032d3c9b-dde9-4f49-8545-2e336b5077e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "def compute_dhash(image, hash_size=8):\n",
    "    resized = cv2.resize(image, (hash_size + 1, hash_size), interpolation=cv2.INTER_LINEAR)\n",
    "    diff = resized[:, 1:] > resized[:, :-1]\n",
    "    return diff.flatten().astype(np.uint8)\n",
    "\n",
    "def hamming_distance(hash1, hash2):\n",
    "    return np.mean(hash1 != hash2)\n",
    "\n",
    "        \n",
    "class Duplicate:\n",
    "    def __init__(self, hash_size=8):\n",
    "        self.image_hashes = {}\n",
    "        self.hash_size=hash_size\n",
    "\n",
    "    def hash_image_folder(self, image_folder):\n",
    "        n_image = 0\n",
    "    \n",
    "        for filename in os.listdir(image_folder):\n",
    "            file_path = os.path.join(image_folder, filename)\n",
    "            \n",
    "            try:\n",
    "                # Load the image and convert to grayscale\n",
    "                image = Image.open(file_path).convert('L')\n",
    "                image = np.array(image)\n",
    "                img_hash = compute_dhash(image, self.hash_size)\n",
    "                self.image_hashes[file_path] = img_hash\n",
    "                n_image += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "                continue\n",
    "        print(f'images hashed: {n_image}')\n",
    "\n",
    "            \n",
    "    def find_near_duplicates(self, threshold=0.1, start_idx=0):\n",
    "        duplicates = defaultdict(list)\n",
    "\n",
    "        # Compare hashes for near-duplicates\n",
    "        file_list = list(self.image_hashes.keys())\n",
    "        for i, file1 in enumerate(file_list):\n",
    "            for j in range(max(i + 1, start_idx), len(file_list)):\n",
    "                file2 = file_list[j]\n",
    "                dist = hamming_distance(self.image_hashes[file1], self.image_hashes[file2])\n",
    "                if dist <= threshold:\n",
    "                    duplicates[file1].append(file2)\n",
    "    \n",
    "        return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e36835-896b-4512-ab99-5312453adf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = Duplicate(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f829e-9efa-4475-a79a-c46c85ab6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"/media/charles/DATA/Programs/datasetManipulation/datasets/Dataset-ViPARE-22/test/images\"\n",
    "dup.hash_image_folder(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa9f53c-c016-483d-b662-86180f02f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"/media/charles/DATA/Programs/datasetManipulation/datasets/Dataset-ViPARE-22/valid/images\"\n",
    "dup.hash_image_folder(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71fb1a0-2480-42a9-ad98-f6cb5dacddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"/media/charles/DATA/Programs/datasetManipulation/datasets/Dataset-ViPARE-22/train/images\"\n",
    "dup.hash_image_folder(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647dc44e-2022-4def-9f66-80280729be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"/media/charles/DATA/Programs/datasetManipulation/datasets/newImages\"\n",
    "dup.hash_image_folder(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039eb1d-0a15-4bb7-b6ad-cdc431291fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = dup.find_near_duplicates(0.1, 345+790+3802)\n",
    "\n",
    "# Print results\n",
    "for image, near_duplicates in duplicates.items():\n",
    "    print(f\"Image: {image}\")\n",
    "    for duplicate in near_duplicates:\n",
    "        print(f\"  -> Near-duplicate: {duplicate}\")\n",
    "print(len(duplicates))\n",
    "sum(list(map(len, duplicates.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728421c-16ba-4dd2-b96b-b14db94eb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "def display_duplicates(duplicates):\n",
    "    def extract_dataset(path):\n",
    "        # Check for \"train\", \"valid\", or \"test\" in the path\n",
    "        if \"train\" in path:\n",
    "            return \"train\"\n",
    "        elif \"valid\" in path:\n",
    "            return \"valid\"\n",
    "        elif \"test\" in path:\n",
    "            return \"test\"\n",
    "        return None\n",
    "\n",
    "    for image_path, near_duplicates in duplicates.items():\n",
    "        original_image = Image.open(image_path)\n",
    "        \n",
    "        num_duplicates = len(near_duplicates)\n",
    "        fig, axes = plt.subplots(1, num_duplicates + 1, figsize=(5 * (num_duplicates + 1), 5))\n",
    "        filename = image_path.split(\"/\")[-1]\n",
    "        print(f\"Original: {extract_dataset(image_path)} - {filename}\")\n",
    "\n",
    "        axes[0].imshow(original_image)\n",
    "        axes[0].axis(\"off\")\n",
    "        \n",
    "        for i, duplicate_path in enumerate(near_duplicates):\n",
    "            duplicate_image = Image.open(duplicate_path)\n",
    "            axes[i + 1].imshow(duplicate_image)\n",
    "            axes[i + 1].axis(\"off\")\n",
    "            filename = duplicate_path.split(\"/\")[-1]\n",
    "            print(f\"Duplicate: {extract_dataset(duplicate_path)} - {filename}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5af3db-9d5b-44d9-b342-cac55ea86149",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_10 = dict(list(duplicates.items())[0:50])\n",
    "display_duplicates(dup_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ecd46-3676-4453-8917-2c13b4257a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
