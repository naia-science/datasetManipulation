{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4b0231-4208-40fd-aadc-4c788382ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff4117-d97f-4962-bdeb-5ce488f9de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from splitDataset import split_large_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c0e4c-3f39-4cf9-8fac-1de4fa526f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fake dataset should have images and labels folder inside\n",
    "path = \"/media/charles/81d75a6a-d733-4070-ad6f-9e7fe046ffab/Programs/datasetManipulation/Notebooks/fake_dataset\"\n",
    "out = split_large_images(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6dc16-fd98-4dfd-9f0e-bc4e66e1735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_with_annotations(images, anns, titles=None, cols=2):\n",
    "    from datasetUtils import colorFromClass\n",
    "    from matplotlib import pyplot as plt\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    \n",
    "    rows = (len(images) + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (image, ann, ax) in enumerate(zip(images, anns, axes)):\n",
    "        if titles is not None:\n",
    "            ax.set_title(titles[i])\n",
    "\n",
    "        #img = cv2.imread(image)\n",
    "        ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert from BGR to RGB for matplotlib\n",
    "\n",
    "        # Read annotation file and draw polygons\n",
    "        cls = 0\n",
    "        for polygon in ann[:]:\n",
    "            polygon *= np.array([image.shape[1], image.shape[0]])\n",
    "            faceColor, contourColor = colorFromClass(cls)\n",
    "            ax.fill(*zip(*polygon), facecolor=faceColor, edgecolor=contourColor, alpha=0.7)\n",
    "\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for j in range(len(images), rows * cols):\n",
    "        axes[j].axis('off')\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a416626-9f2b-46b6-8d65-7c15374a90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images_with_annotations(out[0], out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a3dc8-cbe3-4240-a68b-04ead9e55f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_coords(coords):\n",
    "    coords[..., 0] = coords[..., 0].clip(0, 1.0)  # x\n",
    "    coords[..., 1] = coords[..., 1].clip(0, 1.0)  # y\n",
    "    # Check that the annotation is useful\n",
    "    if np.any(coords[..., 0] > 0) and np.any(coords[..., 1] > 0) and np.any(coords[..., 0]<1.0) and np.any(coords[..., 1]<1.0):\n",
    "        return coords\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def split_img(img, ann, max_size=1280):\n",
    "    w,h,_ = img.shape\n",
    "    nb_splits_w, nb_splits_h = w // max_size, h // max_size\n",
    "    if nb_splits_w == 0 and nb_splits_h == 0:\n",
    "        # no split, return just the basic image\n",
    "        return [img], [ann]\n",
    "    else:\n",
    "        nw, nh = int(w / (nb_splits_w + 1)), int(h / (nb_splits_h + 1))\n",
    "        wcoords = [(i * nw, (i+1) * nw) for i in range(nb_splits_w +1 )]\n",
    "        hcoords = [(i * nh, (i+1) * nh) for i in range(nb_splits_h +1 )]\n",
    "        imgs = []\n",
    "        new_anns = []\n",
    "        for wc in wcoords:\n",
    "            for hc in hcoords:\n",
    "                # split images\n",
    "                imgs.append(img[wc[0]:wc[1], hc[0]:hc[1]])\n",
    "                new_ann = []\n",
    "                xymin = np.array([wc[0]/w, hc[0]/h])[::-1]\n",
    "                xyscale = np.array([w/(wc[1]-wc[0]), h/(hc[1]-hc[0])])[::-1]\n",
    "                # get ann coords\n",
    "                for i, s in enumerate(ann):\n",
    "                    coords = np.array(s)\n",
    "                    coords -= xymin\n",
    "                    coords *= xyscale\n",
    "                    coords = clip_coords(coords)\n",
    "                    if coords is not None:\n",
    "                        new_ann.append(coords)\n",
    "                new_anns.append(new_ann)\n",
    "        \n",
    "        return imgs, new_anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd9376-7271-40df-b6f4-f8c6f1eb7c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"/media/charles/81d75a6a-d733-4070-ad6f-9e7fe046ffab/Programs/datasetManipulation/mergeDataset/test/images/batch_9_000090.jpg\")\n",
    "annotation = \"/media/charles/81d75a6a-d733-4070-ad6f-9e7fe046ffab/Programs/datasetManipulation/mergeDataset/test/labels/batch_9_000090.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694cb9c8-c19d-4cfd-bc7e-07edf5cbfb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = []\n",
    "with open(annotation) as f:\n",
    "    for line in f.readlines():\n",
    "        u = line.split(\" \")[:-1]\n",
    "        anns.append([float(x) for x in u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4d1bd2-2d25-43cf-9f8e-a79de39c7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = split_img(img, anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254a143-80f5-4e18-affc-26c68831ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "[im.shape for im in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea25b1-b166-4c17-9040-60a2a7ca51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ddef7-806a-4a35-b15a-1f0e54628810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def split_large_images(im_dir, max_size=1280):\n",
    "    \"\"\"\n",
    "    Convert segmentation dataset splitting images that have a size larger than 1280 into several\n",
    "\n",
    "    Args:\n",
    "        im_dir (str | Path): Path to image directory to convert.\n",
    "        will generate a new folder \"split\" with the same image and labels directories\n",
    "    Notes:\n",
    "        The input directory structure assumed for dataset:\n",
    "\n",
    "            - im_dir\n",
    "                ├─ 001.jpg\n",
    "                ├─ ..\n",
    "                └─ NNN.jpg\n",
    "            - labels\n",
    "                ├─ 001.txt\n",
    "                ├─ ..\n",
    "                └─ NNN.txt\n",
    "    \"\"\"\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    from ultralytics.data import YOLODataset\n",
    "    from ultralytics.utils import LOGGER\n",
    "    from ultralytics.utils.ops import xywh2xyxy\n",
    "\n",
    "    # NOTE: add placeholder to pass class index check\n",
    "    dataset = YOLODataset(im_dir, data=dict(names=list(range(1000))))\n",
    "    if len(dataset.labels[0][\"segments\"]) > 0:  # if it's segment data\n",
    "        LOGGER.info(\"Segmentation labels detected\")\n",
    "    else:\n",
    "        LOGGER.info(\"Detection labels detected\")\n",
    "\n",
    "    save_dir = Path(im_dir).parent / \"split\"\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    new_im_dir = save_dir / \"images\"\n",
    "    new_im_dir.mkdir(parents=True, exist_ok=True)\n",
    "    new_label_dir = save_dir / \"labels\"\n",
    "    new_label_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    total_num_processed = 0\n",
    "    total_num_generated = 0\n",
    "    \n",
    "    for l in tqdm(dataset.labels, total=len(dataset.labels), desc=\"splitting images\"):\n",
    "        h, w = l[\"shape\"]\n",
    "        boxes = l[\"bboxes\"]\n",
    "        if len(boxes) == 0:  # skip empty labels\n",
    "            continue\n",
    "        total_num_processed += 1\n",
    "        boxes[:, [0, 2]] *= w\n",
    "        boxes[:, [1, 3]] *= h\n",
    "        im = cv2.imread(l[\"im_file\"])\n",
    "        imgs, new_anns = split_img(im, l[\"segments\"])\n",
    "    \n",
    "        for k, (img, new_ann) in enumerate(zip(imgs, new_anns)):\n",
    "            total_num_generated += 1\n",
    "            texts = []\n",
    "            name = Path(l[\"im_file\"]).stem + \"_\" + str(k)\n",
    "            img_file = new_im_dir / (name + Path(l[\"im_file\"]).suffix)\n",
    "            txt_file = new_label_dir / (name + \".txt\")\n",
    "            \n",
    "            cls = l[\"cls\"]\n",
    "            for i, s in enumerate(l[\"segments\"]):\n",
    "                line = (int(cls[i]), *s.reshape(-1))\n",
    "                texts.append((\"%g \" * len(line)).rstrip() % line)\n",
    "            if texts:\n",
    "                with open(txt_file, \"a\") as f:\n",
    "                    f.writelines(text + \"\\n\" for text in texts)\n",
    "            cv2.imwrite(str(img_file.resolve()), img)\n",
    "    LOGGER.info(f\"Generated {total_num_generated} images and labels from {total_num_processed} original images, saved in {save_dir}\")\n",
    "\n",
    "    # returns the last ones for display\n",
    "    return imgs, new_anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807227b0-df4d-4230-993b-b60fa7546664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9425eb6a-70e5-452c-8fbd-ddec63e8b05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503da0b8-a270-48c3-b482-4f763d05ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imm = out[0][2]\n",
    "plt.imshow(cv2.cvtColor(imm, cv2.COLOR_BGR2RGB))\n",
    "cls = 1\n",
    "\n",
    "for polygon in out[1][2]:\n",
    "    poly = polygon * np.array([imm.shape[1]*1.0, imm.shape[0]*1.0])\n",
    "    faceColor, contourColor = colorFromClass(str(int(cls)))\n",
    "    plt.fill(*zip(*poly), facecolor=faceColor, edgecolor=contourColor, alpha=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9921213-6714-445e-aad2-4a0703ac32ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
